# AI/ML Development Rules

## 🧠 Model Development
- **Use appropriate ML frameworks** (PyTorch, TensorFlow, scikit-learn)
- **Implement model versioning** and tracking
- **Use GPU acceleration** when available (CUDA)
- **Optimize model performance** for production use
- **Handle model loading/unloading** efficiently

## 📊 Data Processing
- **Preprocess data appropriately** for ML tasks
- **Handle missing values** and outliers
- **Use proper data validation** techniques
- **Implement data augmentation** when needed
- **Ensure data quality** and consistency

## 🔧 GPU Optimization
- **Check CUDA availability** before GPU operations
- **Use appropriate device placement** (CPU/GPU)
- **Monitor GPU memory usage** and prevent OOM
- **Implement batch processing** for large datasets
- **Use mixed precision** when appropriate

## 📈 Performance Monitoring
- **Track model performance metrics** (accuracy, loss, etc.)
- **Monitor training progress** and convergence
- **Implement early stopping** to prevent overfitting
- **Use appropriate evaluation metrics**
- **Monitor inference latency** and throughput

## 🔒 Model Security
- **Validate model inputs** to prevent adversarial attacks
- **Implement model explainability** when possible
- **Handle model bias** and fairness
- **Secure model artifacts** and weights
- **Implement model access controls**

## 📝 Code Quality
- **Use type hints** for ML functions
- **Add comprehensive docstrings** for models
- **Implement proper error handling** for ML operations
- **Use logging** for training and inference
- **Follow ML best practices** and conventions

## 🧪 Testing
- **Write unit tests** for ML components
- **Test model predictions** with known inputs
- **Validate model outputs** and ranges
- **Test edge cases** and error conditions
- **Implement integration tests** for ML pipelines

## 📚 Documentation
- **Document model architecture** and design decisions
- **Provide usage examples** for models
- **Document training procedures** and hyperparameters
- **Include performance benchmarks** and comparisons
- **Document model deployment** procedures

## 🔄 Model Lifecycle
- **Implement model training** pipelines
- **Use model registries** for version management
- **Implement A/B testing** for model comparison
- **Monitor model drift** and performance degradation
- **Plan model updates** and retraining

## 🌐 Thai Language ML
- **Use Thai language models** when appropriate
- **Handle Thai text preprocessing** correctly
- **Use appropriate Thai tokenization** methods
- **Consider Thai language patterns** in NLP tasks
- **Test with Thai text** thoroughly

## 📊 Data Management
- **Use appropriate data formats** (CSV, JSON, Parquet)
- **Implement data versioning** and tracking
- **Handle large datasets** efficiently
- **Use data pipelines** for preprocessing
- **Implement data validation** and quality checks

## 🔍 Model Interpretability
- **Implement feature importance** analysis
- **Use explainable AI techniques** when possible
- **Provide model explanations** for predictions
- **Document model limitations** and assumptions
- **Handle model uncertainty** appropriately

## 🚀 Deployment
- **Optimize models for production** deployment
- **Implement model serving** APIs
- **Use containerization** for model deployment
- **Monitor model performance** in production
- **Implement model rollback** procedures

## 📈 Scaling
- **Design for horizontal scaling** of ML services
- **Use distributed training** for large models
- **Implement model caching** strategies
- **Optimize inference** for high throughput
- **Use appropriate infrastructure** for ML workloads

## 🔧 Configuration
- **Use configuration files** for model parameters
- **Implement hyperparameter tuning** strategies
- **Use environment variables** for model settings
- **Document configuration options** thoroughly
- **Validate configuration** on startup

## 📊 Monitoring & Alerting
- **Monitor model performance** metrics
- **Track prediction accuracy** and drift
- **Monitor resource usage** (CPU, GPU, memory)
- **Implement alerting** for model issues
- **Maintain model performance** dashboards

## 🛡️ Security
- **Validate all model inputs** thoroughly
- **Implement rate limiting** for model APIs
- **Secure model artifacts** and data
- **Use authentication** for model access
- **Monitor for adversarial attacks**

## 🔄 Continuous Learning
- **Implement online learning** when appropriate
- **Use feedback loops** for model improvement
- **Monitor model performance** over time
- **Plan regular model updates** and retraining
- **Document learning from failures**

---

**Remember:** AI/ML development requires careful attention to data quality, model performance, and production readiness. Always consider the end-user experience and system reliability.
description:
globs:
alwaysApply: false
---
