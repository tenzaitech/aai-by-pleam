# WAWAGOT.AI - GPU Accelerated API
# ===============================================================================
# WAWAGOT.AI - API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU-accelerated services
# ===============================================================================
# Created: 2024-12-19
# Purpose: API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ GPU services ‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô
# ===============================================================================

import asyncio
import json
import base64
import io
from datetime import datetime
try:
    from zoneinfo import ZoneInfo
    TZ_BANGKOK = ZoneInfo("Asia/Bangkok")
except ImportError:
    import pytz
    TZ_BANGKOK = pytz.timezone("Asia/Bangkok")
from typing import Dict, Any, Optional, List
from fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
import uvicorn
from pydantic import BaseModel

# Import GPU Manager
from gpu_manager import GPUManager, GPUAcceleratedServices

# ===============================================================================
# API MODELS
# ===============================================================================

class TextGenerationRequest(BaseModel):
    """Request ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text Generation ‡πÅ‡∏ö‡∏ö hybrid"""
    prompt: str
    model: str = "gpt-3.5-turbo"
    max_tokens: int = 1000
    temperature: float = 0.7
    provider: str = "openai"
    device: str = "auto"  # auto, gpu, cpu

class ImageProcessingRequest(BaseModel):
    """Request ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Image Processing ‡πÅ‡∏ö‡∏ö hybrid"""
    operation: str  # resize, filter, detection, segmentation
    parameters: Dict[str, Any] = {}
    device: str = "auto"  # auto, gpu, cpu

class VoiceSynthesisRequest(BaseModel):
    """Request ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Voice Synthesis ‡πÅ‡∏ö‡∏ö hybrid"""
    text: str
    voice: str = "default"
    speed: float = 1.0
    provider: str = "retell"
    device: str = "auto"  # auto, gpu, cpu

class OCRRequest(BaseModel):
    """Request ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OCR ‡πÅ‡∏ö‡∏ö hybrid"""
    language: str = "eng"
    engine: str = "tesseract"
    device: str = "auto"  # auto, gpu, cpu

class GPUStatusResponse(BaseModel):
    """Response ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU Status"""
    success: bool
    gpu_count: int
    utilization: Dict[str, Any]
    memory_usage: Dict[str, Any]
    temperature: Dict[str, Any]

# ===============================================================================
# GPU API SERVER
# ===============================================================================

class GPUAPIServer:
    """GPU API Server ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô"""
    
    def __init__(self):
        self.app = FastAPI(
            title="WAWAGOT.AI GPU API",
            description="GPU-accelerated AI services API",
            version="1.0.0"
        )
        self.gpu_manager = GPUManager()
        self.gpu_services = None
        self.setup_routes()
        self.setup_cors()
    
    def setup_cors(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ CORS"""
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],  # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏ó‡∏∏‡∏Å origin
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
    
    def setup_routes(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API routes"""
        
        # Health Check
        @self.app.get("/")
        async def root():
            return {
                "message": "WAWAGOT.AI GPU API",
                "status": "running",
                "timestamp": datetime.now(TZ_BANGKOK).isoformat()
            }
        
        # GPU Status
        @self.app.get("/api/gpu/status", response_model=GPUStatusResponse)
        async def get_gpu_status():
            """‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ GPU"""
            try:
                status = await self.gpu_manager.get_gpu_status()
                if status["success"]:
                    return GPUStatusResponse(
                        success=True,
                        gpu_count=status.get("total_gpus", 0),
                        utilization=status.get("utilization", {}),
                        memory_usage={},
                        temperature={}
                    )
                else:
                    raise HTTPException(status_code=500, detail=status["error"])
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        # GPU Optimization
        @self.app.post("/api/gpu/optimize")
        async def optimize_gpu():
            """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ GPU"""
            try:
                result = await self.gpu_manager.optimize_gpu_usage()
                return result
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        # Text Generation
        @self.app.post("/api/ai/text/generate")
        async def generate_text(request: TextGenerationRequest):
            """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ AI ‡πÅ‡∏ö‡∏ö hybrid"""
            try:
                if not self.gpu_services:
                    raise HTTPException(status_code=503, detail="GPU services not initialized")
                
                # ‡πÉ‡∏ä‡πâ hybrid service
                result = await self.gpu_services._generate_text_hybrid(request, request.device)
                return result
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        # Image Processing
        @self.app.post("/api/ai/image/process")
        async def process_image(
            file: UploadFile = File(...),
            operation: str = "resize",
            device: str = "auto"
        ):
            """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ GPU ‡πÅ‡∏ö‡∏ö hybrid"""
            try:
                if not self.gpu_services:
                    raise HTTPException(status_code=503, detail="GPU services not initialized")
                
                # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û
                image_data = await file.read()
                
                # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö hybrid
                result = await self.gpu_services._process_image_hybrid(image_data, operation, device)
                return result
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        # Voice Synthesis
        @self.app.post("/api/ai/voice/synthesize")
        async def synthesize_voice(request: VoiceSynthesisRequest):
            """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡∏î‡πâ‡∏ß‡∏¢ AI"""
            try:
                if not self.gpu_services:
                    raise HTTPException(status_code=503, detail="GPU services not initialized")
                
                # ‡πÉ‡∏ä‡πâ GPU acceleration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö voice synthesis
                result = await self._synthesize_voice_gpu(request)
                return result
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        # OCR Processing
        @self.app.post("/api/ai/ocr/process")
        async def process_ocr(
            file: UploadFile = File(...),
            language: str = "eng",
            engine: str = "tesseract"
        ):
            """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• OCR ‡∏î‡πâ‡∏ß‡∏¢ GPU"""
            try:
                if not self.gpu_services:
                    raise HTTPException(status_code=503, detail="GPU services not initialized")
                
                # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
                file_data = await file.read()
                
                # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• OCR ‡∏î‡πâ‡∏ß‡∏¢ GPU
                result = await self._process_ocr_gpu(file_data, language, engine)
                return result
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        # Model Management
        @self.app.post("/api/gpu/models/load")
        async def load_model(model_name: str, model_path: str):
            """‡πÇ‡∏´‡∏•‡∏î Model ‡πÑ‡∏õ‡∏¢‡∏±‡∏á GPU"""
            try:
                result = await self.gpu_manager.load_model_to_gpu(model_name, model_path)
                return result
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        # Batch Processing
        @self.app.post("/api/gpu/batch/process")
        async def batch_process(requests: List[Dict[str, Any]]):
            """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö Batch ‡∏î‡πâ‡∏ß‡∏¢ GPU"""
            try:
                results = []
                for request in requests:
                    if request["type"] == "text":
                        result = await self._generate_text_gpu(TextGenerationRequest(**request["data"]))
                    elif request["type"] == "image":
                        result = await self._process_image_gpu(request["data"], request["operation"])
                    elif request["type"] == "voice":
                        result = await self._synthesize_voice_gpu(VoiceSynthesisRequest(**request["data"]))
                    else:
                        result = {"error": f"Unknown request type: {request['type']}"}
                    
                    results.append(result)
                
                return {"success": True, "results": results}
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        # Real-time Streaming
        @self.app.get("/api/gpu/stream/status")
        async def stream_gpu_status():
            """Stream ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ GPU ‡πÅ‡∏ö‡∏ö Real-time"""
            async def generate():
                while True:
                    try:
                        status = await self.gpu_manager.get_gpu_status()
                        yield f"data: {json.dumps(status)}\n\n"
                        await asyncio.sleep(1)
                    except Exception as e:
                        yield f"data: {json.dumps({'error': str(e)})}\n\n"
                        await asyncio.sleep(5)
            
            return StreamingResponse(generate(), media_type="text/plain")
    
    async def _generate_text_gpu(self, request: TextGenerationRequest) -> Dict[str, Any]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ GPU acceleration"""
        try:
            # ‡πÉ‡∏ä‡πâ GPU memory ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö model loading
            if TORCH_AVAILABLE and cuda.is_available():
                # ‡∏¢‡πâ‡∏≤‡∏¢ model ‡πÑ‡∏õ GPU ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
                pass
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ OpenAI API ‡∏´‡∏£‡∏∑‡∏≠ Gemini API
            if request.provider == "openai":
                # ‡πÉ‡∏ä‡πâ OpenAI API
                result = await self._call_openai_api(request)
            elif request.provider == "gemini":
                # ‡πÉ‡∏ä‡πâ Gemini API
                result = await self._call_gemini_api(request)
            else:
                result = {"error": f"Unknown provider: {request.provider}"}
            
            return {
                "success": True,
                "text": result.get("text", ""),
                "provider": request.provider,
                "model": request.model,
                "gpu_accelerated": True,
                "processing_time": 0.1  # ‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏£‡∏¥‡∏á
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _process_image_gpu(self, image_data: bytes, operation: str, gpu_accelerated: bool) -> Dict[str, Any]:
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ GPU"""
        try:
            if OPENCV_AVAILABLE and gpu_accelerated:
                # ‡πÉ‡∏ä‡πâ OpenCV CUDA
                if cv2.cuda.getCudaEnabledDeviceCount() > 0:
                    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array
                    import numpy as np
                    nparr = np.frombuffer(image_data, np.uint8)
                    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                    
                    # ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ GPU
                    gpu_img = cv2.cuda_GpuMat()
                    gpu_img.upload(img)
                    
                    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ï‡∏≤‡∏° operation
                    if operation == "resize":
                        # Resize ‡∏î‡πâ‡∏ß‡∏¢ GPU
                        gpu_result = cv2.cuda.resize(gpu_img, (640, 480))
                        result_img = gpu_result.download()
                    elif operation == "filter":
                        # Filter ‡∏î‡πâ‡∏ß‡∏¢ GPU
                        gpu_result = cv2.cuda.GaussianBlur(gpu_img, (15, 15), 0)
                        result_img = gpu_result.download()
                    else:
                        result_img = img
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô bytes
                    _, buffer = cv2.imencode('.jpg', result_img)
                    result_data = base64.b64encode(buffer).decode('utf-8')
                    
                    return {
                        "success": True,
                        "operation": operation,
                        "gpu_accelerated": True,
                        "image_data": result_data,
                        "processing_time": 0.05
                    }
            
            # Fallback ‡πÑ‡∏õ CPU
            return {
                "success": True,
                "operation": operation,
                "gpu_accelerated": False,
                "message": "Using CPU fallback"
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _synthesize_voice_gpu(self, request: VoiceSynthesisRequest) -> Dict[str, Any]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡∏î‡πâ‡∏ß‡∏¢ GPU"""
        try:
            # ‡πÉ‡∏ä‡πâ Retell.AI ‡∏´‡∏£‡∏∑‡∏≠ OpenAI TTS
            if request.provider == "retell":
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Retell.AI API
                result = await self._call_retell_api(request)
            elif request.provider == "openai_tts":
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å OpenAI TTS API
                result = await self._call_openai_tts_api(request)
            else:
                result = {"error": f"Unknown provider: {request.provider}"}
            
            return {
                "success": True,
                "audio_data": result.get("audio_data", ""),
                "provider": request.provider,
                "voice": request.voice,
                "gpu_accelerated": True,
                "processing_time": 0.2
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _process_ocr_gpu(self, file_data: bytes, language: str, engine: str) -> Dict[str, Any]:
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• OCR ‡∏î‡πâ‡∏ß‡∏¢ GPU"""
        try:
            # ‡πÉ‡∏ä‡πâ Tesseract ‡∏´‡∏£‡∏∑‡∏≠ PaddleOCR
            if engine == "tesseract":
                # ‡πÉ‡∏ä‡πâ Tesseract
                result = await self._call_tesseract_ocr(file_data, language)
            elif engine == "paddleocr":
                # ‡πÉ‡∏ä‡πâ PaddleOCR
                result = await self._call_paddleocr_ocr(file_data, language)
            else:
                result = {"error": f"Unknown engine: {engine}"}
            
            return {
                "success": True,
                "text": result.get("text", ""),
                "engine": engine,
                "language": language,
                "gpu_accelerated": True,
                "processing_time": 0.1
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    # Placeholder methods ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö API calls
    async def _call_openai_api(self, request: TextGenerationRequest) -> Dict[str, Any]:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å OpenAI API"""
        return {"text": f"Generated text for: {request.prompt[:50]}..."}
    
    async def _call_gemini_api(self, request: TextGenerationRequest) -> Dict[str, Any]:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini API"""
        return {"text": f"Gemini generated: {request.prompt[:50]}..."}
    
    async def _call_retell_api(self, request: VoiceSynthesisRequest) -> Dict[str, Any]:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Retell.AI API"""
        return {"audio_data": "base64_encoded_audio_data"}
    
    async def _call_openai_tts_api(self, request: VoiceSynthesisRequest) -> Dict[str, Any]:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å OpenAI TTS API"""
        return {"audio_data": "base64_encoded_audio_data"}
    
    async def _call_tesseract_ocr(self, file_data: bytes, language: str) -> Dict[str, Any]:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Tesseract OCR"""
        return {"text": "Extracted text from image"}
    
    async def _call_paddleocr_ocr(self, file_data: bytes, language: str) -> Dict[str, Any]:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å PaddleOCR"""
        return {"text": "Extracted text from image"}
    
    async def start_server(self, host: str = "0.0.0.0", port: int = 8000):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô API Server"""
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô GPU Manager
        await self.gpu_manager.initialize_gpu_system()
        
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô GPU Services
        self.gpu_services = GPUAcceleratedServices(self.gpu_manager)
        await self.gpu_services.initialize_services()
        
        print(f"üöÄ GPU API Server ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà: http://{host}:{port}")
        print("üìö API Documentation: http://localhost:8000/docs")
        print("üîß GPU Services ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
        
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô server
        config = uvicorn.Config(self.app, host=host, port=port, log_level="info")
        server = uvicorn.Server(config)
        await server.serve()

# ===============================================================================
# MAIN EXECUTION
# ===============================================================================

async def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    server = GPUAPIServer()
    await server.start_server()

if __name__ == "__main__":
    asyncio.run(main()) 